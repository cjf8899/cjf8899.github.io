---
title:  "DeepLabV2 paper review"
last_modified_at: 2020-09-09 00:00:00 -0400
categories: 
  - Segmentation
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs
> Liang-Chieh Chen, et al. "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs.": Proceedings of the IEEE Transactions on Pattern Analysis and Machine Intelligence. 2018.

# DeepLabV2 리뷰

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 노현철 입니다. 
제가 이번에 리뷰할 논문은 **"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"** 입니다.


## Introduction
![initial](https://user-images.githubusercontent.com/53032349/92452060-85f79480-f1f8-11ea-8a6c-e8894093901d.png)

요번 논문을 읽기전에 DeepLabV1 논문을 읽지 않아서 인터넷을 간단하게 찾아보았습니다. 검색을 해보니 DeepLabV1에서 주장하는 내용은 CONDITIONAL RANDOM FIELDS(CRF) 라는 내용 한가지 였습니다. semantic segmentation은 픽셀단위의 조밀한 예측이 필요함으로 CRF를 후처리 과정으로 사용하여 픽셀단위 예측의 정확도를 더 높일 수 있게 되었습니다. 특히 fully connected CRF를 사용하면 위 그림과 같이 detail이 살아 있는 결과를 얻을 수 있습니다.

![initial](https://user-images.githubusercontent.com/53032349/92452133-9c055500-f1f8-11ea-819b-54dee8da4a6e.png)

또한 이러한 CRF를 한번만 사용하는 것이 아니라  여러번 사용하게 된다면 조금 더 좋은 결과를 얻을 수 있습니다.

이 논문에서는 DeepLabv1을 보완하고자 CRF를 포함한 3가지 이슈가 있습니다.

1) CONDITIONAL RANDOM FIELDS (CRF)

2) Atrous convolution (dilated convolution)

3) Atrous Spatial Pyramid Pooling (ASPP)

### Atrous convolution (dilated convolution)

![initial](https://user-images.githubusercontent.com/53032349/92452456-0918ea80-f1f9-11ea-9c9a-be3ac451160b.png)

기존 DCNN에서 receptive field을 확장 시키려면 pooling 후 convolution 했어야 했습니다. 이것은 feature들의 크기를 줄일 뿐만 아니라 연산량 또한 증가 시켰습니다. 이 논문에서 말하는 Atrous convolution은 이러한 이러한 현상들을 줄여 준다고 합니다. 이 Atrous convolution은 dilated convolution과 이름만 다를 뿐 같은 개념이라고 보시면 됩니다. Atrous convolution는 기존 convolution 과 연산량은 같지만 receptive field 가 확장되는 효과를 가져옵니다. 위에 사진을 보면 rate만큼 간격을 벌리고 그 간격은 0으로 만들어 버려서 receptive field의 크기를 확장 시키는 것 입니다.
![initial](https://user-images.githubusercontent.com/53032349/92452483-1209bc00-f1f9-11ea-8311-92f09f5ca8e3.png)

사진으로 비교해 보아도 pooling + conv 보단 Atrous convolution을 사용하는 것이 receptive field가 확장되있는 것을 직관적으로 볼 수 있습니다.

### Atrous Spatial Pyramid Pooling (ASPP)

![initial](https://user-images.githubusercontent.com/53032349/92452504-1afa8d80-f1f9-11ea-9b25-880acefd1afc.png)

Spatial Pyramid Pooling(SPP)은 sppnet에서 영감을 받고 쓰였다고 하는데 이 논문 spp에 Atrous convolution을 더하여 aspp이라는 방법을 제시 하였습니다.
Atrous convolution을 사용하여 각각의 rate 값들을 각각 {6, 12, 18. 24} 로 하여 Pyramid Pooling 하였습니다. 그리고 이들의 결과들을 합쳐 각각의 receptive field를 수용하여 여러크기의 물체를 인식하는데 좋은 결과를 가져왔습니다.


### DeepLab v1, v2 비교

![initial](https://user-images.githubusercontent.com/53032349/92452535-23eb5f00-f1f9-11ea-9e48-666f8dda26d1.png)

DeepLab v1, v2를 구조를 사진으로 비교해보자면 우선 input image가 들어가면 v1은 기본적인 DCNN을 사용하였지만 v2는 Atrous convolution을 사용하여 DCNN을 하였습니다. 그 결과 score map의 크기가 v1보단 v2가 더 크게 나오는것을 볼 수 있습니다. 다음은 bi-linear interpolation방법을 통해 원본의 크기만큼 upsample하였습니다. 그리고 fully connected CRF을 사용하여 정확도를 한층 높였습니다.

## Experimental

![initial](https://user-images.githubusercontent.com/53032349/92452577-2e0d5d80-f1f9-11ea-95bf-11426541d57c.png)

실험은 'fc6' layer의 rate값들을 각각 다르게 하여 실험 하였습니다. 그 결과 Kernel: 7x7, rate: 4, CRF사용 하였을때가 Kernel: 3x3, rate: 12, CRF사용 하였을 때와 성능이 같은걸 볼 수 있습니다. 그러나 전자의 실험이 후자의 실험보다 parameters도 많고, speed(img/sec)도 느린것으로 나타났습니다. 그래서 DeepLab-LargeFOV은 kernel size 3×3, r = 12 을 사용하게 되었습니다.

![initial](https://user-images.githubusercontent.com/53032349/92452607-382f5c00-f1f9-11ea-8543-9b58ce4a49fa.png)

두번째 실험은 위 실험에서 구한 DeepLab-LargeFOV와 ASPP안에 들어가는 Atrous convolution rate값들을 다르게 하고 비교하는 실험입니다.
ASPP-S는 rate = {2, 4, 8, 12}, ASPP-L는 rate = {6, 12, 18, 24}입니다. 
실험 결과 rate값이 ASPP-S보다 높게잡은 ASPP-L의 결과가 더 좋은 것으로 나타났습니다.
![initial](https://user-images.githubusercontent.com/53032349/92452647-42515a80-f1f9-11ea-8497-fb1ea9dafc74.png)

## 후기
어쩌다보니 deeplab v1을 읽지않고 v2를 먼저 읽게 되었는데 나름 v1의 내용이 많이 없어서 다행이였습니다. 다음번에는 v3를 읽고 리뷰를 써보도록 하겠습니다..!
