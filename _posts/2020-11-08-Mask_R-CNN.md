---
title:  "Mask R-CNN paper review"
last_modified_at: 2020-11-08 00:00:00 -0400
categories: 
  - Segmentation
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# Mask R-CNN
> Kaiming He, et al. ["Mask R-CNN."](https://arxiv.org/abs/1703.06870) Proceedings of the IEEE International Conference on Computer Vision (ICCV)2017.

# Mask R-CNN 리뷰

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 노현철 입니다. 
제가 이번에 리뷰할 논문은 **"Mask R-CNN"** 입니다.

# Abstract
-우리는 이미지의 객체들을 효율적으로 감지하는 동시에 고품질 마스크 또한 생성하는 Mask R-CNN을 제시한다.
-Mask R-CNN은 Faster R-CNN에서 확장(마스크 예측하는 모듈)하였다.<br>
-Mask R-CNN은 학습이 간단, Faster R-CNN의 약간의 오버헤드만 추가한다.<br>
-COCO의 챌린지 분야(instance segmentation, boundingbox object detection, person keypoint detection)에서 최고의 결과를 보였다.

<img src="https://user-images.githubusercontent.com/53032349/98468155-845c4400-221c-11eb-918e-201343d0023d.jpg" width="50%" height="50%" title="70px" alt="memoryblock">

# Introduction
-Fast/Faster RCNN, FCN(Fully Convolutional Network)을 사용하는 유연하고 견고한 instance segmentation 프레임워크를 개발
![initial](https://user-images.githubusercontent.com/53032349/98468289-309e2a80-221d-11eb-9615-a8c2563f9641.jpg)
-Instance segmentation는 이미지의 모든 개체를 감지하는 동시에 정확히 분할 해야하기 때문에 어렵다.<br>
-여기서의 목표는 개별로 객체를 분류하고 bounding box를 사용하여 semantic segmentation하는 것<br>
-우리는 간단하고 유연하며 빠른 시스템으로 이 전의 성능들을 능가한다. <br>
-기존 Faster R-CNN의 관심영역(RoI)에 작은 FCN을 추가하여 pixel-topixel 방식으로 마스크를 예측한다.<br>
-Mask R-CNN은 Faster R-CNN 프레임워크를 고려할 때 구현 및 학습이 간단, 작은 오버헤드만 추가함으로 빠르게 수행할 수 있다.<br>
-Faster RCNN은 네트워크 입력과 출력 사이의 픽셀 간 정렬이 설계되지 않았다.(object detection이라 그런 것 같다) <br>
-첫째, RoIPool작업이 필요하다. 이 논문에서는 RoIPool작업(대략전인 공간을 양자화 하는것) 대신 RoIAlign를 사용하였다.(양자화가 없는 것)<br>
-이로인해 10 %에서 50 %까지 향상시켜주었다.<br>
-둘째, 마스크와 클래스를 분리하는 것이 필수적이다.<br>
-일단 이미지에서 각 클래스별 마스크를 예측하고, 관심영역(RoI)의 classification 을 통해 카테고리를 예측한다.<br>
-F-CN으로 segmentation과 classification를 결합한다.<br>
-COCO에서 탁월한 효과를 얻었다.<br>
-프레임 당 약 200ms로 실행, 8-GPU에서 COCO train은 1 ~ 2 일 걸렸다.<br>
-마지막으로 COCO keypoint dataset에서도 우수한 성능이 나왔다.<br>

# Related Work
-Instance Segmentation: 우리의 방법은 마스크와 클래스 레이블의 병렬 예측을 기반으로합니다. 다른 segmenting instances논문들은 느리거나 안 좋거나 문제점들이 많음

# Mask R-CNN
-Faster R-CNN에는 각 후보 객체에 대해 두 개의 outputs, class label, bounding-box offset이 있는데 여기에 object mask를 출력하는 CNN(FCN) 추가. 직관적인 아이디어다.<br>
-또한, 미세한 공간 출력을 위해 핵심요소를 소개 할 것이다.<br>
-공식적으로 train에서는 multi-task loss를 사용한다. L = L_cls + L_box + L_mask<br>
-Ground-Truth에서 클래스 k와 관련된 RoI의 경우 Lmask는 k 번째 마스크에서만 정의. (다른 마스크 출력은 loss에 기여하지 않음). = RoI에서 찾은 클래스를 바탕으로 마스크를 채택, 다른 마스크는 신경 안쓴다는 말<br>
-네트워크는 경쟁없이 모든 클래스의 대한 마스크를 생성 할 수 있다. classification하여 라벨을 예측하고 라벨에 대한 마스크를 선택하는 방식이다.<br>

# Mask Representation
-FCN을 사용하여 각 RoI에서 m × m 마스크를 예측한다. <br>
-fc레이어를 사용했던 이전과 달리m × m을 유지 하면서도 더 적은 parameters, 더 좋은 성능을 가져왔다.<br>
-이러한 pixel-to-pixel으로 공간에 대한 대응을 충실하게 유지하기 위해 잘 정렬해야 한다.(=RoI가 기능이 좋아야 한다.)<br>

# RoIAlign
<img src="https://user-images.githubusercontent.com/53032349/98468511-203a7f80-221e-11eb-8a1f-e012d5fee439.png" width="80%" height="80%" title="70px" alt="memoryblock">
<img src="https://user-images.githubusercontent.com/53032349/98468518-2d576e80-221e-11eb-8d5a-31a72e6f12d2.png" width="80%" height="80%" title="70px" alt="memoryblock">
<img src="https://user-images.githubusercontent.com/53032349/98468532-39433080-221e-11eb-96c4-ba137705af9c.png" width="80%" height="80%" title="70px" alt="memoryblock">

-RoIPool은 단순히 양자화 하는 것. 소수가 나오면 반올림하여 계산.<br>
-하지만 이러한 계산은 정렬이 불량하다.(=RoI가 안 좋다.) 이로인해 성능에 대한 부정적인 영향이 끼친다.
<img src="https://user-images.githubusercontent.com/53032349/98468571-6a236580-221e-11eb-963a-8d654a8bbc8a.png" width="80%" height="80%" title="70px" alt="memoryblock">
<img src="https://user-images.githubusercontent.com/53032349/98468586-727ba080-221e-11eb-9cfe-57a929adecf6.png" width="80%" height="80%" title="70px" alt="memoryblock">

-이를 해결하기 위해 양자화가 아닌 RoIAlign을 제안. RoI경계의 양자화를 피하고 bilinear interpolation(이중선형보간)을 통해 소수점까지 계산하여 정확한 결과를 얻는다.<br>
-RoIAlign은 크게 성능을 크게 개선하였다.
<img src="https://user-images.githubusercontent.com/53032349/98468605-8fb06f00-221e-11eb-8a1b-0cf380984ff9.png" width="80%" height="80%" title="70px" alt="memoryblock">

# Network Architecture
-Mask R-CNN은 여러 아키텍쳐를 합친 네트워크이고 두 가지로 나눈다.<br>
1) convolutional backbone architecture used for feature extraction over an entire image

2) the network head for bounding-box recognition (classification and regression) and mask prediction that is applied separately to each RoI
<img src="https://user-images.githubusercontent.com/53032349/98469173-604f3180-2221-11eb-96f7-7254a993f3ec.png" width="50%" height="50%" title="70px" alt="memoryblock">


-네트워크 깊이에 따른 백본 아키텍쳐로는 ResNet 및 ResNeXt 깊이 50 또는 101가 사용되었다.

# Implementation Details
* image-centric training
* Images are resized(800 pixels)
* GPU 1개당 2
* learning rate of 0.02
* 160k iterations, 120k iteration에서 Lr 10배 감소
* weight decay of 0.0001
* momentum of 0.9
* ResNeXt 사용할때는 starting learning rate of 0.01

# Experiments: Instance Segmentation
![initial](https://user-images.githubusercontent.com/53032349/98469260-c1770500-2221-11eb-8662-bbd291844bb5.png)
-AP 옆에 있는 숫자는 IoU의 수치이다. S, M, L는 객체의 크기이다.
![initial](https://user-images.githubusercontent.com/53032349/98469227-98ef0b00-2221-11eb-8f77-33aa6649dcf4.png)
![initial](https://user-images.githubusercontent.com/53032349/98469268-cc319a00-2221-11eb-9588-2a3543e04f4c.png)

-사람의 키포인트 찾는 챌린지에서도 우수한 성능을 보임
![initial](https://user-images.githubusercontent.com/53032349/98469299-fc793880-2221-11eb-9c27-944dd872bc34.png)
<img src="https://user-images.githubusercontent.com/53032349/98469303-fe42fc00-2221-11eb-9313-5d4cc7eb40b3.png" width="80%" height="80%" title="70px" alt="memoryblock">
