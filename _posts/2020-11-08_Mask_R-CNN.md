---
title:  "Mask R-CNN paper review"
last_modified_at: 2020-11-08 00:00:00 -0400
categories: 
  - Segmentation
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# Mask R-CNN
> Kaiming He, et al. ["Mask R-CNN."](https://arxiv.org/abs/1703.06870) Proceedings of the IEEE International Conference on Computer Vision (ICCV)2017.

# Mask R-CNN 리뷰

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 노현철 입니다. 
제가 이번에 리뷰할 논문은 **"Mask R-CNN"** 입니다.

# Abstract
우리는 이미지의 객체들을 효율적으로 감지하는 동시에 고품질 마스크 또한 생성하는 Mask R-CNN을 제시한다.<br>
Mask R-CNN은 Faster R-CNN에서 확장(마스크 예측하는 모듈)하였다.<br>
Mask R-CNN은 학습이 간단, Faster R-CNN의 약간의 오버헤드만 추가한다.<br>
COCO의 챌린지 분야(instance segmentation, boundingbox object detection, person keypoint detection)에서 최고의 결과를 보였다.
![initial](https://user-images.githubusercontent.com/53032349/98468155-845c4400-221c-11eb-918e-201343d0023d.jpg)

# Introduction
Fast/Faster RCNN, FCN(Fully Convolutional Network)을 사용하는 유연하고 견고한 instance segmentation 프레임워크를 개발
![initial](https://user-images.githubusercontent.com/53032349/98468289-309e2a80-221d-11eb-9615-a8c2563f9641.jpg)
Instance segmentation는 이미지의 모든 개체를 감지하는 동시에 정확히 분할 해야하기 때문에 어렵다.<br>
여기서의 목표는 개별로 객체를 분류하고 bounding box를 사용하여 semantic segmentation하는 것<br>
우리는 간단하고 유연하며 빠른 시스템으로 이 전의 성능들을 능가한다. <br>
기존 Faster R-CNN의 관심영역(RoI)에 작은 FCN을 추가하여 pixel-topixel 방식으로 마스크를 예측한다.<br>
Mask R-CNN은 Faster R-CNN 프레임워크를 고려할 때 구현 및 학습이 간단, 작은 오버헤드만 추가함으로 빠르게 수행할 수 있다.<br>
Faster RCNN은 네트워크 입력과 출력 사이의 픽셀 간 정렬이 설계되지 않았다.(object detection이라 그런 것 같다) <br>
첫째, RoIPool작업이 필요하다. 이 논문에서는 RoIPool작업(대략전인 공간을 양자화 하는것) 대신 RoIAlign를 사용하였다.(양자화가 없는 것)<br>
이로인해 10 %에서 50 %까지 향상시켜주었다.<br>
둘째, 마스크와 클래스를 분리하는 것이 필수적이다.<br>
일단 이미지에서 각 클래스별 마스크를 예측하고, 관심영역(RoI)의 classification 을 통해 카테고리를 예측한다.<br>
FCN으로 segmentation과 classification를 결합한다.<br>
COCO에서 탁월한 효과를 얻었다.<br>
프레임 당 약 200ms로 실행, 8-GPU에서 COCO train은 1 ~ 2 일 걸렸다.<br>
마지막으로 COCO keypoint dataset에서도 우수한 성능이 나왔다.<br>

# Related Work
Instance Segmentation: 우리의 방법은 마스크와 클래스 레이블의 병렬 예측을 기반으로합니다. 다른 segmenting instances논문들은 느리거나 안 좋거나 문제점들이 많음

# Mask R-CNN
Faster R-CNN에는 각 후보 객체에 대해 두 개의 outputs, class label, bounding-box offset이 있는데 여기에 object mask를 출력하는 CNN(FCN) 추가. 직관적인 아이디어다.<br>
또한, 미세한 공간 출력을 위해 핵심요소를 소개 할 것이다.<br>
공식적으로 train에서는 multi-task loss를 사용한다. L = L_cls + L_box + L_mask<br>
Ground-Truth에서 클래스 k와 관련된 RoI의 경우 Lmask는 k 번째 마스크에서만 정의. (다른 마스크 출력은 loss에 기여하지 않음). = RoI에서 찾은 클래스를 바탕으로 마스크를 채택, 다른 마스크는 신경 안쓴다는 말<br>
네트워크는 경쟁없이 모든 클래스의 대한 마스크를 생성 할 수 있다. classification하여 라벨을 예측하고 라벨에 대한 마스크를 선택하는 방식이다.<br>

# Mask Representation
FCN을 사용하여 각 RoI에서 m × m 마스크를 예측한다. <br>
fc레이어를 사용했던 이전과 달리m × m을 유지 하면서도 더 적은 parameters, 더 좋은 성능을 가져왔다.<br>
이러한 pixel-to-pixel으로 공간에 대한 대응을 충실하게 유지하기 위해 잘 정렬해야 한다.(=RoI가 기능이 좋아야 한다.)<br>

# RoIAlign
<table>
  <tr>
    <td>![initial](https://user-images.githubusercontent.com/53032349/98468511-203a7f80-221e-11eb-8a1f-e012d5fee439.png)</td>
    <td>![initial](https://user-images.githubusercontent.com/53032349/98468518-2d576e80-221e-11eb-8d5a-31a72e6f12d2.png)</td>
    <td>![initial](https://user-images.githubusercontent.com/53032349/98468532-39433080-221e-11eb-96c4-ba137705af9c.png)</td>
  </tr>
