---
title:  "AdaIN paper review"
last_modified_at: 2021-01-01 00:00:00 -0400
categories: 
  - Generative Adversarial Network
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# AdaIN
> Xun Huang, et al. ["Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization."](https://arxiv.org/abs/1703.06868) Proceedings of the IEEE International Conference on Computer Vision (ICCV)2017.

# AdaIN 리뷰

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 노현철 입니다. 
제가 이번에 리뷰할 논문은 **"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization"** 입니다.

# Abstract
-콘텐츠 이미지를 다른 이미지 스타일로 렌터링하는 알고리즘 도입<br>
-하지만 프레임워크에서는 느린 프레임워크에서 최적화 되어 실제 적용이 제한된다.<br>
-신경 스타일 전송속도를 높이기 위해 feed-forward neural networks가 제안되었다. 하지만 속도향상의 따른 대가는 고정된 스타일만 적용가능하고 새로운 스타일은 적용 불가능이다.<br>
-이 논문은 새로운 스타일에 대해서도 실시간으로 전송할 수 있고, 간단하면서도 효과적인 접근방식을 제시한다.<br>
-우리의 핵심방식은 콘텐츠의 특징의 평균, 분산을 새로운 스타일의 평균, 분산으로 정렬하는 novel adaptive instance normalization (AdaIN) 이다.<br>
-스타일의 제한없이 가장 빠른 속도를 가진다.<br>
-또한, 우리는 content-style trade-off, style interpolation, color & spatial controls와 같은 사용자 제어를 허용한다.<br>

# Introduction
-DNN은 콘텐츠와 이미지 스타일 정보도 인코딩을 한다. 또한 둘을 분리할 수 있다. 콘텐츠를 유지하면서 스타일 변경이 가능하다. 그러나 매우 느리다.<br>
-스타일 전송을 가속화하기 위해 많은 노력을 기울였다.<br>
-이 문제를 다루는 논문은 유한한 스타일 세트로 제한되거나 단일 스타일(새로운 스타일) 전송은 훨씬 느리다.<br>
-우리의 작업은 이러한 근본적인 유연성, 속도를 해결하는 알고리즘을 제시한다.<br>
-우리의 알고리즘은 가장 빠른 feed-forward와 유사하며, 새로운 스타일을 real-time으로 전송할 수 있다.<br>
-우리의 메소드는 instance normalization에서 영감을 받았으며, feed-forward에서 놀라운 효과를 얻었다<br>
-instance normalization는 이미지의 스타일 정보를 전달하는 것으로 밝혀진 특성 통계를 정규화하여 스타일 정규화를 수행한다는 새로운 해석을 제안하였다(다른 논문에서)<br>
-이러한 해석을 동기화 하여 간단한 확장, adaptive instance normalization (AdaIN)를 소개한다.<br>
-콘텐츠(input image)와 스타일이 주워지면 AdaIN은 단순히 스타일의 입력과 일치하도록 콘텐츠의 평균, 분산을 조정한다.<br>
-실험을 통해 AdaIN은 기능 통계를 전송하여 콘텐츠 전자, 스타일 후자를 효과적으로 결합한다. 이후 AdaIN 출력을 이미지 공간으로 반전하여 최종 이미지를 생성한다.<br>
-우리의 방법은 기존 방식(DNN) 보다 3배 빠르고, 프로세서를 수정하지 않고도 사용제 제어가 가능하다.<br>


# Related Work
-스타일 전송은 다양한 방법들이 있고, 대부분 시간을 소비하는 대신 비디오 스타일의 품질을 향상시켰다.<br>
-느린 최적화 속도로 인해 최신GPU를 사용하더라도 느리다. 따라서 모바일 애플리케이션으로는 실용적이지 못 하다.<br>
-해결방법으로는 f최소한으로 훈련된 feed-forward신경망으로 대체하였고, 약 3배 빠르게 real-time 애플리이케이션으로 최적화하였다. 또한 여러 가지 방법들로 인해 새로운 스타일을 전송할 수 있는 아키텍쳐들이 제안되었지만, 새로운 스타일에 대해서는 적응할 수 없었다<br>었다.
-가장 최근 새로운 스타일 전송방식이 나왔지만(가장 일치하는 스타일로 적용) 병목현상을 발생 시킨다. <br>
-우리의 접근방식은 이와 같이 새로운 스타일 전송 하지만 1-2배 빠르다.<br>
-스타일 전송의 다른 핵심 문제는 스타일 손실 함수이다.<br>
-MRF loss, adversarial loss, histogram loss, CORAL loss, MMD loss, and distance between channel-wise mean and variance를 사용하는 목표는 스타일 이미지와 합성 이미지의 일부기능 통계를 일치 시키는 것<br>
-심층 모델링으로는 GAN의 프레임 워크에 대한 다양한 개선이 제안되었다.<br>

# Background
## Batch Normalization
-feed-forward 네트워크에 배치에 따라 Normalization를 적용하여 네트워크의 훈련속도를 가속화 하도록 설계 되었지만 생성 이미지 모델링(이미지 생성)에서도 효과적인 것으로 밝혀졌습니다.<br>
<img src="https://user-images.githubusercontent.com/53032349/103442129-cd69cb00-4c96-11eb-989c-6166bc145c68.png" width="80%" height="80%" title="70px" alt="memoryblock">

## Instance Normalization
-단순히 Batch Normalization를 Instance Normalization로 바꿔도 상당한 개선을 달성할 수 있음을 발견<br>
<img src="https://user-images.githubusercontent.com/53032349/103442148-f2f6d480-4c96-11eb-9f32-d1143f601590.png" width="80%" height="80%" title="70px" alt="memoryblock">

## Conditional Instance Normalization
-기존 논문에서는 각 스타일에 대해 서로다른 매개변수 감마, 베타를 학습하는 conditional instance normalization을 제안하였다.<br>
-몇가지로 구성된 스타일(S)를 사용하여 값을 변경해줌으로써 감마, 베타값을 변경시켜 완전히 다른 스타일의 이미지를 생성 할 수 있다.<br>
-하지만 이 또한 fixed된 스타일의 이미지에서만 적용되고 새로운 스타일에 대해서는 적용이 불가<br>
<img src="https://user-images.githubusercontent.com/53032349/103442169-1d489200-4c97-11eb-9132-db4cecbbb10d.png" width="80%" height="80%" title="70px" alt="memoryblock">

## Interpreting Instance Normalization
-(Conditional) instance normalization는 큰 성공이지만 잘 작동하는 이유는 아직까지도 파악하기 어렵다. <br>
-여기서 중요한점은 instance normalization에서 감마, 베타 값만 조정하여도 이미지의 스타일을 완전히 변경할 수 있다는 점이다.<br>
-채널별로 평균 및 분산을 포함한 다른 많은 통계를 일치시키는 것이 스타일 전달에도 효과적인 것을 기존 논문에서 알아내었다.<br>
-그림1.a를 보면 Batch Normalization보다 Instance Normalization가 더욱 빠르게 수렴하였다. <br>
-그림1.b를 보면 기존 논문의 설명이 잘못되었다라고 지적하고 있다. contrast문제였다면 비슷하게 나와야 하는데 더욱 벌어진 것을 볼 수 있다.<br>
-그림1.c를 보면 스타일 Normalization이 이미 되어있는 것을 비교해 보았을 때는 차이가 거의 없는 것을 보고 스타일 부분에서 Instance Normalization이 효과가 좋다는 것을 알 수 있다.<br>

<img src="https://user-images.githubusercontent.com/53032349/103442189-584ac580-4c97-11eb-80ea-a9f986a427bb.png" width="80%" height="80%" title="70px" alt="memoryblock">

## Adaptive Instance Normalization
-AdaIN은 콘텐츠 입력 x와 스타일 입력 y를 수신하고 x의 채널 별 평균 및 분산을 y의 값과 일치하도록 정렬<br>
-스타일 입력에 대해서 affine 매개변수를 적응형으로 계산한다.<br>
-짧게 말해서는 채널 별 평균 및 분산을 전송하여 스타일 전송을 수행한다. 기존의 스타일 스왑 레이어와 유사한 역항이다. <br>
-스타일 스왑 레이어는 시간과 메모리를 많이 소모하지만 AdaIN은 IN과 같이 간단하고 계산 비용이 거이 추가되지 않는다.(이러하여 real-time에 사용하는 듯)<br>
<img src="https://user-images.githubusercontent.com/53032349/103442187-4ec15d80-4c97-11eb-8ff5-bf207b48e75b.png" width="80%" height="80%" title="70px" alt="memoryblock">


# Experimental Setup
## Training
-MS-COCO as content images <br>
-WikiArt as style images<br>
-80,000 training examples<br>
-adam optimizer<br>
-batch size of 8 content-style image pairs<br>
-pre-trained VGG19 <br>
-combination of the content loss Lc and the style loss Ls with the style loss weight λ<br>
<img src="https://user-images.githubusercontent.com/53032349/103442247-d313e080-4c97-11eb-980d-87bbfca9d479.png" width="80%" height="80%" title="70px" alt="memoryblock">

# Results
-아래 그림을 보듯이 기존 논문(Gatys et a)보다는 로스가 높지만 기존 논문은 real-time에서 사용할 수 없고 모바일 플랫폼과는 어울리지 않는다. 하지만 우리는 가능하다.
<img src="https://user-images.githubusercontent.com/53032349/103442304-559ca000-4c98-11eb-8047-dde62e041de8.png" width="80%" height="80%" title="70px" alt="memoryblock">
-테이블 1은 속도는 거의 리얼타임과 가깝고 스타일도 무제한으로 입력이 가능하다.
<img src="https://user-images.githubusercontent.com/53032349/103442374-e8d5d580-4c98-11eb-8c11-1a3a1360c575.png" width="80%" height="80%" title="70px" alt="memoryblock">
-아래 그림을 보듯이 퀄리티는 거의 비슷하다.
<img src="https://user-images.githubusercontent.com/53032349/103442310-60efcb80-4c98-11eb-9e18-2845928955e6.png" width="80%" height="80%" title="70px" alt="memoryblock">
-아래 그림은 사용자에 따라 가중치를 다르게 적용하여 커스텀 할 수 있다.
<img src="https://user-images.githubusercontent.com/53032349/103442379-f4c19780-4c98-11eb-8ecd-fd75b89f005a.png" width="80%" height="80%" title="70px" alt="memoryblock">
-아래 그림은 4가지의 스타일을 섞어 적용 할 수 있다.
<img src="https://user-images.githubusercontent.com/53032349/103442388-0efb7580-4c99-11eb-9e3d-7832aa9f54bf.png" width="80%" height="80%" title="70px" alt="memoryblock">
-아래 그림은 배경과 인물의 스타일을 다르게 적용 가능하다.
<img src="https://user-images.githubusercontent.com/53032349/103442399-20dd1880-4c99-11eb-9c79-b3fe31873892.png" width="80%" height="80%" title="70px" alt="memoryblock">
-결과사진 
<img src="https://user-images.githubusercontent.com/53032349/103442428-5a158880-4c99-11eb-990e-9b802e8d4689.png" width="80%" height="80%" title="70px" alt="memoryblock">

