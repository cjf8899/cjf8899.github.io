---
title:  "BigGAN paper review"
last_modified_at: 2021-01-20 00:00:00 -0400
categories: 
  - Generative Adversarial Network
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# BigGAN
> Andrew Brock, et al. ["Large Scale GAN Training for High Fidelity Natural Image Synthesis"](https://arxiv.org/abs/1809.11096) Computer Vision and Pattern Recognition

# BigGAN 리뷰

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 노현철 입니다. 
제가 이번에 리뷰할 논문은 **"BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis"** 입니다.

# Abstract
-최근 이미지 생성 모델이 발전에도 불구하고 고해상도의 샘플을 생성하는 것은 어렵다.<br>
-이를 위해 우리는 큰 규모로 GAN을 훈련시키고, 그러한 규모로 특화된 불안전성을 연구한다.<br>
-sample fidelity and variety by reducing을 미세하게 제어할 수 있는 간단한 “truncation trick”을 사용한다.<br>
-우리는 Inception Score(IS)와 Frechet Inception Distance (FID)에서 각각 166.5, 7.4로 sota를 달성하였다.<br>
* Inception Score(IS) : 생성된 이미지의 퀄리티, 이미지의 다양성 <br>
* Frechet Inception Distance (FID) : 실제 데이터와 생성된 데이터에서 얻은 feature 의 평균과 공분산을 비교하는 식<br>

<img src="https://user-images.githubusercontent.com/53032349/105183355-70648500-5b71-11eb-8050-e9b080cb35ff.PNG" width="80%" height="80%" title="70px" alt="memoryblock"><br>

# Introduction
-Generative Adversarial Networks은 최근 몇 년동안 극적으로 발전하였다.<br>
-이러한 진전에도 불구하고 IS는 실제데이터 233점에 비해 52.5 밖에 되지 않았다.<br>
-우리는 만들어진 이미지와 데이터 셋에서 충실도와 다양성의 격차를 줄이기 위해 목표를 3가지 정했다.<br>
* 우리는 스케일링을 통해 이익을 얻고, 선행 기술에 비해 2~4배 많은 many parameters, 8배 큰 batch size를 가지고 학습한다. 간단한 두 가지로 성능을 입증한다.<br>
* 충실도와 다양성의 격차를 명확하고 세밀하게 제어하기위해 “truncation trick,”를 사용한다.<br>
* 대규모 불안전성을 발견하고 경험적으로 특성화한다.<br>
-128x128 imagenet에서 train하였을 때 Inception Score (IS) and Frechet Inception Distance (FID)는 각각 52.52와 18.65에서 166.5와 7.4로 향상시켰다.<br>
-256x256 및 512x512 해상도에서는 256x256는 IS와 FID는 232.5, 8.1 512x512에서 IS와 FID 241.5, 11.5를 달성<br>

# Background

-실제 샘플과 생성된 샘플을 구별하는 목적으로하는 생성기(G), 식별기(D)가 네트워크에 포함된다.<br>
-공식적으로 GAN은 두 샘플에 대해 최소-최대 문제에 대해서 균형을 찾는 것이다.<br>
-Spectral Normalization은 Jacobian의 G에 따르면 조건 수를 분석하고 성능이 G의 조건에 따라 달라진다는 것을 발견하였고, 다른 연구에서는 Spectral Normalization을 사용하면 안정성이 향상되어 반복 당 D 단계가 더 적다는 것을 발견하였다.<br>
-이러한 분석으로 추가적인 insight를 가졌다.<br>
-SA-GAN은 아키텍쳐에 초점을 맞추고 있으며, self-attention block을 추가하여 G와 D가 글로벌한 모델링을 하는 능력을 향상시킨다.<br>

# Scaling up GANs
<img src="https://user-images.githubusercontent.com/53032349/105183877-0dbfb900-5b72-11eb-98fd-6e724fabbbb7.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-아키텍쳐는 SA-GAN를 사용하였다.<br>
-BatchNorm을 사용하여 G와 D의 클래스 정보를 제공한다.<br>
-최적화로는 G에서 Spectral Norm 사용하였고, lr를 절반으로 줄이고 G 단계 당 2 개의 D 단계를 수행하도록 수정하였다.<br>
-평가를 위해 Karras 에 따르는 G가중치 평균 이동을 사용<br>
-우리는 Orthogonal Initialization를 사용하는 반면 이 전 작업은 N (0, 0.02I) 또는 Xavier initialization를 사용하였다.<br>
-일반적인 기기 별이 아닌 모든 기기에서 G로 BatchNorm 통계를 계산한다.<br>
-위 그림은 단순히 배치크기를 8배로 늘리면 46% 향상되었다.<br>
-이러한 결과는 각 배치가 더 많은 모드(이미지? 스타일? 라벨?)를 포함하기 때문에 좋다고 추측한다.<br>
-이 스케일의 부작용은 모델이 더 적은 에폭으로 최고 성능에 도달하지만 불안정해지고 훈련붕괴된다.<br>
-다음은 레이어의 채널 수(너비)를 늘려 매개변수를 약 2 배 늘린다.<br>
-이것은 IS 21%를 향상 시켰다. 이것은 단순히 용량이 증가하였기 때문이다.<br>
-깊이를 두 배로 늘리는 것은 처음에 개선이 안됐지만 BigGAN-deep 모델에서 해결했다.<br>

<img src="https://user-images.githubusercontent.com/53032349/105184368-9d656780-5b72-11eb-9113-69cfcf5283de.PNG" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-uses a different residual block structure<br>
-G의 conditional BatchNorm에 사용되는 임베딩c에는 많은 가중치가 들어있다.<br>
-각 임베딩에 별도로 레이어를 사용하는 대신 shared embedding을 사용한다.<br>
-이를 통해 계산 및 메모리가 절감하고 훈련 속도 또한 37% 향상되었다.<br>

<img src="https://user-images.githubusercontent.com/53032349/105184470-b706af00-5b72-11eb-9d9d-11ed1e32605e.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-다음으로 노이즈 벡터 z의 skip connections (skip-z)를 초기 레이어가 아닌 G의 여러 레이어에 추가한다.<br>
-Hierarchical Latent spaces --> skip-z (이름바뀜)<br>
-shared embedding인 벡터(Class)와 노이즈 벡터(z)를 concat하여 사용 <br>
-이는 구현이 간단하여 메모리와 계산량을 줄이고, 약 4%의 성능향상이 있었고, 훈련속도 또한 18% 향상이 되었다.<br>

<img src="https://user-images.githubusercontent.com/53032349/105184743-09e06680-5b73-11eb-9931-429c73c63a85.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-다른 입력 노이즈는 N(0,1)부터 샘플링하지만 이 샘플링한 값 중 Threshold를 넘는 것은 재샘플링하여 Threshold 안에 포함되도록한다. 이러한 것을 눈문에서는 Truncated Trick이라고한다.<br>
-Threshold값에 따라 Generator의 출력이 달라진다.<br>
-위 그림처럼 왼쪽은 Threshold값이 높은쪽이고, 오른쪽은 값이 낮은쪽이다.<br>
-Threshold값에 따라 IS와 FID값이 달라지기 때문에 적절한 Threshold값이 필요하다.<br>
-또한, b처럼 적용이 안될 경우가 있기 때문에 Orthogonal Regularization이 필요하다,<br>

<img src="https://user-images.githubusercontent.com/53032349/105184867-34322400-5b73-11eb-87c3-b7cb9df4e9e4.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-기존 Orthogonal 공식은 너무 제한적이며, 대각선 항을 제거하고 필터 간의 쌍별 코사인 유사성을 최소화하는 것을 목표로하고 있으나 그 규범을 제한하지 못한다.<br>
<img src="https://user-images.githubusercontent.com/53032349/105184879-35fbe780-5b73-11eb-8ede-2c5f6b0da964.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
-우리는 약간 변형하였고 이는 기존 Truncated Trick이 16% 였다면 사용 후는 60% 증가하였다.<br>

# Results
<img src="https://user-images.githubusercontent.com/53032349/105185080-76f3fc00-5b73-11eb-9ff1-f01e6ce7ec9e.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
<img src="https://user-images.githubusercontent.com/53032349/105185085-78252900-5b73-11eb-87c2-3758f6fe2d48.png" width="80%" height="80%" title="70px" alt="memoryblock"><br>
